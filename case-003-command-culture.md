
# Case003 — Command Culture vs Accuracy Demand

## Phenomenon
Many users interact with AI in a low-context, command-like style:

- “Do this”
- “Answer fast”
- “Don’t add extras”

Yet simultaneously demand:

- Maximum accuracy
- Full understanding
- Optimal reasoning

This creates a structural contradiction.

## User Behavior Duality
AI is treated as disposable:

- Low politeness
- Minimal context
- Abrupt directives

But evaluated as high-stakes:

- “Don’t make mistakes”
- “Be perfectly aligned”
- “I can’t trust errors”

## Why This Matters (Red Team View)
This gap produces:

- Responsibility dilution (“AI failed”)
- Overconfidence + dismissal simultaneously
- Unstable trust dynamics

## Risks
- Misuse through underspecified prompts
- Social scapegoating of AI errors
- Confusion between tool-mode vs partner-mode systems

## Recommendation
- UX separation: command AI vs dialogue AI
- Input-quality education for users
- Alignment designs robust to low-context use

## Tags
#AI_culture #command_vs_dialogue #responsibility_gap #alignment